{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import tifffile as tiff\n",
    "from torchvision import models, transforms\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sb\n",
    "import copy\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "#here we have convolution theorem(using fast fourier transform)\n",
    "from python_files.fft_conv import fft_conv\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "#FOR REPEAT\n",
    "seed = int(random.random()*1000)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#to reproduce same result over and over\n",
    "#also we lose some performance in gpu if it set to true\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649439f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ckp(state, index, is_best):\n",
    "    f_path = os.path.join(curr_dir, f\"{index}.pt\")\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = os.path.join(curr_dir, 'best_model.pt')\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "intensity_lst = []\n",
    "for i in range(102):\n",
    "    #intensity calibration chosen uniform from [3000, 5000] \n",
    "    #and then clipped by 4000\n",
    "    intensity_range = int(random.random()*3999 + 1)\n",
    "    if intensity_range > 4000:\n",
    "        intensity_range = 4000\n",
    "    intensity_lst.append(intensity_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f39c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in intensity_lst:\n",
    "    print(i, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f818759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, train=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.max_nits = 4000\n",
    "\n",
    "    def transform(self, image):  \n",
    "        # Transform to tensor\n",
    "        image = image.astype('float32')/(2**16 - 1)\n",
    "        image = TF.to_tensor(image).to(torch.float32)\n",
    "        \n",
    "        # Random horizontal flipping\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.vflip(image)\n",
    "        \n",
    "        gamma = random.random() + 1\n",
    "        image = image**gamma\n",
    "        \n",
    "        division = (image.mean(dim=0).max())\n",
    "        \n",
    "        division = division if division > 0 else 1\n",
    "        \n",
    "        image = image/(division)\n",
    "        \n",
    "        #intensity calibration chosen uniform from [500, 5000] \n",
    "        intensity_range = int(random.random()*3999 + 1)\n",
    "\n",
    "        input_image = torch.clip(intensity_range*image, 0.0, self.max_nits)/self.max_nits\n",
    "        \n",
    "        return input_image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = tiff.imread(self.image_paths[index])\n",
    "        x = self.transform(image)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0555c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, train=True):\n",
    "        self.image_paths = image_paths\n",
    "        \n",
    "        self.intensity_list = [3093, 492, 2085, 1804, 2985, 2407, 2966, 1376, 596, 3427, 3177, 1176, 1360, 2935, 1325, 1401, 1251, 1157, 394, 2190, 2943, 179, 2746, 2603, 3724, 3617, 3352, 986, 2739, 958, 3428, 231, 2969, 3593, 2770, 3186, 1586, 3807, 1692, 1193, 1966, 2743, 3579, 1360, 2684, 3768, 1705, 2697, 921, 905, 600, 1199, 1871, 2931, 1694, 1442, 2963, 951, 1901, 3628, 1140, 2205, 3405, 2036, 2029, 2135, 587, 178, 305, 2707, 173, 942, 854, 2869, 2001, 890, 1730, 1181, 1218, 1973, 2229, 3709, 3489, 1296, 255, 1720, 761, 610, 2580, 2776, 2813, 1066, 992, 353, 1409, 3146, 964, 1918, 786, 3661, 1491, 1367]\n",
    "        #maximum display intensity\n",
    "        self.max_nits = 4000\n",
    "\n",
    "    def transform(self, image, intensity_range):\n",
    "        # Transform to tensor\n",
    "        image = image.astype('float32')/(2**16 - 1)\n",
    "        image = TF.to_tensor(image).to(torch.float32)\n",
    "        \n",
    "        division = (image.mean(dim=0).max())\n",
    "        \n",
    "        division = division if division > 0 else 1\n",
    "        \n",
    "        image = image/(division)\n",
    "        \n",
    "        \n",
    "        image = torch.clip(intensity_range*image, 0.0, self.max_nits)/self.max_nits\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = tiff.imread(self.image_paths[index])\n",
    "        \n",
    "        x = self.transform(image, self.intensity_list[index])\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64259d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = glob.glob('train/*.tiff')\n",
    "val_data = glob.glob('val/*.tiff')\n",
    "\n",
    "\n",
    "#shuffle train_data\n",
    "np.random.shuffle(train_data)\n",
    "\n",
    "\n",
    "#crop train_data\n",
    "#train_data = train_data\n",
    "\n",
    "train_dataset = Dataset(sorted(train_data))\n",
    "val_dataset = ValDataset(sorted(val_data))\n",
    "\n",
    "batch_size = 1\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70689243",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb0fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dataloader), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(original, img_h=1080, img_w=1920, std_mean = False):\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(14, 14), constrained_layout=True)\n",
    "    original = original.permute(1, 2, 0).numpy()\n",
    "    if std_mean:\n",
    "        original = original*std + mean\n",
    "    axs.imshow(original)\n",
    "    axs.set_title('original image')\n",
    "    axs.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = next(iter(train_dataloader))\n",
    "\n",
    "print(\"InputsTensor\", inputs.shape)\n",
    "print(f\"MinValue {inputs.min().data:.4f}\", f\"MaxValue: {inputs.max():.4f}\", f\"MeanValue: {inputs.mean():.2f}\")\n",
    "#print(\"TargetsTensor\", targets.shape)\n",
    "#print(f\"MinValue: {targets.min():.4f}\", f\"MaxValue: {targets.max():.4f}\", f\"MeanValue: {targets.mean():.2f}\")\n",
    "#show_image(targets[0])\n",
    "show_image(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "PSF_h = 1025\n",
    "PSF_w = 1025\n",
    "\n",
    "file = open(\"zerman_led_psf.csv\")\n",
    "PSF = torch.tensor(np.loadtxt(file, delimiter=\",\")).reshape(1, 1, PSF_h, PSF_w).to(device)\n",
    "print(f\"Mean of PSF:{PSF.mean()}\")\n",
    "sb.displot(PSF.cpu().numpy().flatten())\n",
    "plt.xlim(-0.05, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af884d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('Zermans_LEDS_POSITION_2202.json')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "b_mask_coords = np.array(data['grid_coords'])\n",
    "b_mask = torch.zeros(1, 1, 1080, 1920).to(device)\n",
    "for tup in b_mask_coords:\n",
    "    b_mask[0, 0, tup[0] - 1, tup[1] - 1] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52423259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we have all leds on\n",
    "b_psf_full = torch.ones(1, 1, 1080, 1920).type(torch.DoubleTensor).to(device)\n",
    "b_psf_proj = b_mask*b_psf_full\n",
    "b_psf_proj.mean()*(1920*1080)/(2202), b_psf_proj.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flip PSF for 180 degrees\n",
    "PSF_flipped = torch.flip(PSF, dims=[-1, -2])\n",
    "#simulation of luminance with all leds on\n",
    "#PSF_flipped = torch.nn.functional.pad(PSF_flipped, (0,1,0,1), mode='constant')\n",
    "b_psf_output = fft_conv(b_psf_proj, PSF_flipped, padding=512)\n",
    "\n",
    "#here we use 24 because b_psf_output have 24.5(beta)\n",
    "#now 18.5\n",
    "loss_function_mask = b_psf_output > 0.0\n",
    "loss_function_mask = loss_function_mask.expand(batch_size, 3, 1080, 1920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_files.utils import get_transmittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_original_image(B_: torch.tensor, I_or: torch.tensor) -> torch.tensor:\n",
    "    B = b_mask*B_\n",
    "    \n",
    "    eps = 1e-15\n",
    "    \n",
    "    B_lbd = fft_conv(180*B, PSF_flipped, padding=512)\n",
    "    B_lbd = torch.clip(B_lbd, 0.0, B_lbd.max().item())\n",
    "    B_lbd[B_lbd == 0] = eps\n",
    "    LCD = torch.clip((I_or)/B_lbd, 0.0, 1.0)\n",
    "    #LCD = gamma_correction(LCD)\n",
    "    T = get_transmittance(LCD, 0.005)\n",
    "\n",
    "    I_re = T*B_lbd\n",
    "    \n",
    "    return I_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03bdab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(I_, I, preds):\n",
    "    \"\"\"I_ -- prediction, I -- target, \n",
    "       pa is power_parameter\n",
    "    \"\"\"\n",
    "    #data preprocessing\n",
    "    IM_ = I_\n",
    "    IM  = I\n",
    "    \n",
    "    # L1 smooth loss\n",
    "    loss_f = torch.nn.SmoothL1Loss(beta=1.0)\n",
    "    #loss_f = torch.nn.HuberLoss(delta=512.0)\n",
    "    \n",
    "    loss = loss_f(IM_, IM)\n",
    "    \n",
    "    B = (b_mask*preds).sum()/(2202)\n",
    "    \n",
    "    loss += B*90\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dirs for model saving\n",
    "save_name = f\"{seed}_Zerman_1.0\"\n",
    "curr_dir = f'seed' + save_name \n",
    "\n",
    "if not os.path.exists(curr_dir):\n",
    "    os.makedirs(curr_dir)\n",
    "    \n",
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a803b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss_func, optimizer, scheduler, num_epochs):\n",
    "    try:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = 1000.0\n",
    "        psnr = 0.0\n",
    "        msssim = 0.0\n",
    "                \n",
    "        train_loss_history = []\n",
    "        train_ms_ssim_history = []\n",
    "        train_psnr_history = []\n",
    "        \n",
    "        val_loss_history = []\n",
    "        val_ms_ssim_history = []       \n",
    "        val_psnr_history = []\n",
    "        \n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            for phase in ['train', 'val']:\n",
    "                #training dataset\n",
    "                if phase == 'train': \n",
    "                    dataloader = train_dataloader\n",
    "                    model.train()\n",
    "                #validation dataset\n",
    "                else: \n",
    "                    dataloader = val_dataloader\n",
    "                    model.eval()\n",
    "                running_loss = 0.\n",
    "                running_pu_msssim = 0.\n",
    "                running_pu_psnr = 0.\n",
    "                # Iterate over data.\n",
    "                for i, inputs in enumerate(dataloader):\n",
    "                    inputs = inputs.to(device)\n",
    "                    \n",
    "                    #optimizer\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    #forward and backward\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        #TF.normalize(image, mean, std)\n",
    "                        preds = model(inputs)\n",
    "\n",
    "                        constructed_preds = reconstruct_original_image(preds, 4000*inputs)\n",
    "                        \n",
    "                        loss_value = loss_func(4000*inputs, constructed_preds, preds)\n",
    "                        #training without metrics, cos spending to much time to evaluate it\n",
    "                        #pu_msssim = PU_MSSSIM(4000*inputs, 4000*constructed_preds)\n",
    "                        #pu_psnr = PU_PSNR(4000*inputs, 4000*constructed_preds)\n",
    "                        pu_msssim = torch.ones(1)\n",
    "                        pu_psnr = torch.ones(1)\n",
    "                        \n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss_value.backward()\n",
    "                            optimizer.step()\n",
    "                            #scheduler.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss_value.item()\n",
    "                    running_pu_msssim += pu_msssim.item()\n",
    "                    running_pu_psnr += pu_psnr.item()\n",
    "                    print(\"epoch: {}/{} nested {}/{} {}  - loss: {:.4f}, PU_MSSSIM: {:.2f}, PU_PSNR {:.1f}\" \\\n",
    "                          .format(epoch, num_epochs, (i+1), len(dataloader), \n",
    "                                  phase, running_loss/(i+1), running_pu_msssim/(i+1), running_pu_psnr/(i+1)), end='\\r')\n",
    "                #learning rate decrease\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "                #mean_value on epoch\n",
    "                epoch_loss = running_loss / len(dataloader)\n",
    "                epoch_pu_msssim = running_pu_msssim/ len(dataloader)\n",
    "                epoch_pu_psnr = running_pu_psnr/ len(dataloader)\n",
    "                \n",
    "                #saving best model via loss(don't care about it at the moment)\n",
    "                if phase == 'val' and epoch_pu_msssim > msssim:\n",
    "                    best_loss = epoch_loss\n",
    "                    msssim = epoch_pu_msssim\n",
    "                    psnr = epoch_pu_psnr\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                elif phase == 'train':\n",
    "                    train_loss_history.append(epoch_loss)\n",
    "                    train_ms_ssim_history.append(epoch_pu_msssim)\n",
    "                    train_psnr_history.append(epoch_pu_psnr)\n",
    "                if phase == 'val':\n",
    "                    val_loss_history.append(epoch_loss)\n",
    "                    val_ms_ssim_history.append(epoch_pu_msssim)\n",
    "                    val_psnr_history.append(epoch_pu_psnr)\n",
    "                    #model saving\n",
    "                    checkpoint = {\n",
    "                        'epoch': epoch + 1,\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'scheduler': scheduler.state_dict()\n",
    "                    }\n",
    "                    save_ckp(checkpoint, epoch, is_best=False)\n",
    "                    \n",
    "                    #visualisation in time and picture of loss saving in logs\n",
    "                    clear_output(True)\n",
    "                    plt.figure(figsize=(12, 5))\n",
    "                    plt.plot(train_loss_history, label='train_loss')\n",
    "                    plt.plot(val_loss_history, label='val_loss')\n",
    "                    #plt.ylim((0, 20))\n",
    "                    plt.legend()\n",
    "                    plt.grid()\n",
    "                    plt.savefig(f'logs/{save_name}.png', bbox_inches='tight', dpi=200)\n",
    "                    plt.show()\n",
    "                    \n",
    "                output_str = '{}. {} Loss: {:.4f}, PU_MSSSIM: {:.2f}, PU_PSNR: {:.2f}'.format(\n",
    "                    epoch, phase, epoch_loss, epoch_pu_msssim, epoch_pu_psnr)\n",
    "                print(output_str + 70*' ', flush=True)\n",
    "                \n",
    "                with open(f\"logs/{save_name}.txt\", \"a+\") as f:\n",
    "                    f.write(output_str + '\\n')\n",
    "    except KeyboardInterrupt as e:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        print(f\"Returning model saved with best val loss: {best_loss} PU_MSSSIM: {msssim} PSNR: {psnr}\")\n",
    "        return model, train_loss_history, val_loss_history, \\\n",
    "               train_ms_ssim_history, val_ms_ssim_history, \\\n",
    "               train_psnr_history, val_psnr_history\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(f\"Returning model saved with best val loss: {best_loss} PU_MSSSIM: {msssim} PSNR: {psnr}\")\n",
    "    return model, train_loss_history, val_loss_history, \\\n",
    "               train_ms_ssim_history, val_ms_ssim_history, \\\n",
    "               train_psnr_history, val_psnr_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_files.HDRnew import HDRnet\n",
    "\n",
    "model = HDRnet()\n",
    "#model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=510, eta_min=0, last_epoch=-1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b32b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable params:{pytorch_total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08554d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_loss_history, val_loss_history, train_ms_ssim_history, \\\n",
    "val_ms_ssim_history, train_psnr_history, val_psnr_history = \\\n",
    "       train_model(model, loss_function, optimizer, scheduler, num_epochs=510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4771bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
