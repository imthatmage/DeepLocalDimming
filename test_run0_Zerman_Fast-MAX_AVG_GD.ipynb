{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models, transforms\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sb\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "import tifffile as tiff\n",
    "\n",
    "#here we have convolution theorem(using fast fourier transform)\n",
    "from python_files.fft_conv import fft_conv\n",
    "\n",
    "#changes crop in dataset and dataset folder and saving\n",
    "\n",
    "device = 'cpu' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dirs for model saving\n",
    "test_dir = f'test_reconstruction'\n",
    "test_lcd_dir = f'test_lcd'\n",
    "test_b_dir = f'test_b_reconstruction'\n",
    "test_visual_dir = f'test_visual'\n",
    "os.makedirs(test_dir)\n",
    "os.makedirs(test_b_dir)\n",
    "os.makedirs(test_visual_dir)\n",
    "os.makedirs(test_lcd_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, train=True):\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "    def transform(self, image):\n",
    "        # Transform to tensor\n",
    "        #cr = T.CenterCrop((1080, 1920))\n",
    "        #image = cr(image)\n",
    "        image = TF.to_tensor(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #image = tiff.imread(self.image_paths[index])\n",
    "        image = (tiff.imread(self.image_paths[index])).astype('float32')\n",
    "        x = self.transform(image)\n",
    "        return x, self.image_paths[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = glob.glob('train/data/*.tiff')# + glob.glob('DIV2K_valid_HR/*.png')\n",
    "test_data = glob.glob('srgb_linearized_f32/*.tif')\n",
    "test_data = test_data\n",
    "\n",
    "test_dataset = Dataset(sorted(test_data))\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=False, num_workers=3, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataloader), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "PSF_h = 1025\n",
    "PSF_w = 1025\n",
    "\n",
    "file = open(\"zerman_led_psf.csv\")\n",
    "PSF = torch.tensor(np.loadtxt(file, delimiter=\",\")).reshape(1, 1, PSF_h, PSF_w).to(device)\n",
    "print(f\"Mean of PSF:{PSF.mean()}\")\n",
    "sb.displot(PSF.cpu().numpy().flatten())\n",
    "plt.xlim(-0.05, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('Zermans_LEDS_POSITION_2202.json')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "b_mask_coords = np.array(data['grid_coords'])\n",
    "b_mask = torch.zeros(1, 1, 1080, 1920).to(device)\n",
    "#putting values to leds positions\n",
    "b_mask[0, 0][(b_mask_coords - 1).T] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we have all leds on\n",
    "b_psf_full = torch.ones(1, 1, 1080, 1920).type(torch.DoubleTensor).to(device)\n",
    "b_psf_proj = b_mask*b_psf_full\n",
    "b_psf_proj.mean()*(1920*1080)/(2202), b_psf_proj.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flip PSF for 180 degrees\n",
    "PSF_flipped = torch.flip(PSF, dims=[-1, -2])\n",
    "#simulation of luminance with all leds on\n",
    "#PSF_flipped = torch.nn.functional.pad(PSF_flipped, (0,1,0,1), mode='constant')\n",
    "b_psf_output = fft_conv(180*b_psf_proj, PSF_flipped, padding=512)\n",
    "\n",
    "#here we use 24 because b_psf_output have 24.5(beta)\n",
    "#now 18.5\n",
    "loss_function_mask = b_psf_output > 2700\n",
    "loss_function_mask = loss_function_mask.expand(1, 3, 1080, 1920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Opening JSON file\n",
    "f = open('hex_coords.json')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "hex_coords = np.array(data['hex_coords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_files.utils import get_transmittance, tensor_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_reconstruct_original_image(I_or: torch.tensor) -> torch.tensor:\n",
    "    B = torch.zeros(1, 1, 1080, 1920).to(device)\n",
    "    eps = 1e-15\n",
    "    \n",
    "    summer = 0\n",
    "    #print(\"Start Iterations:\")\n",
    "    for i, tup0 in enumerate(b_mask_coords):\n",
    "        new_coords = np.copy(hex_coords)\n",
    "        new_coords[:, 0] = np.maximum(np.minimum(new_coords[:, 0] - 1 + tup0[0], 1079), 0)\n",
    "        new_coords[:, 1] = np.maximum(np.minimum(new_coords[:, 1] - 1 + tup0[1], 1919), 0)\n",
    "        \n",
    "        B[0, 0, tup0[0] - 1, tup0[1] - 1] = (I_or[0].mean(dim=0)[new_coords.T].max())/4000\n",
    "        #print(f\"Iterations: {i}\", end='\\r')\n",
    "    #print(\"End Iterations\" + 70 * ' ')\n",
    "        \n",
    "    B_lbd = fft_conv(180*B, PSF_flipped, padding=512)\n",
    "    B_lbd = torch.clip(B_lbd, 0.0, B_lbd.max().item())\n",
    "    B_lbd[B_lbd == 0] = eps\n",
    "    LCD = torch.clip((I_or)/B_lbd, 0.0, 1.0)\n",
    "    #LCD = gamma_correction(LCD)\n",
    "    T = get_transmittance(LCD, 0.005)\n",
    "\n",
    "    #always between 0.0 and 1.0\n",
    "    I_re = T*B_lbd\n",
    "    \n",
    "    return I_re, LCD, B_lbd, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_reconstruct_original_image(I_or: torch.tensor) -> torch.tensor:\n",
    "    B = torch.zeros(1, 1, 1080, 1920).to(device)\n",
    "    eps = 1e-15\n",
    "    \n",
    "    #print(\"Start Iterations:\")\n",
    "    for i, tup0 in enumerate(b_mask_coords):\n",
    "        new_coords = np.copy(hex_coords)\n",
    "        new_coords[:, 0] = np.maximum(np.minimum(new_coords[:, 0] - 1 + tup0[0], 1079), 0)\n",
    "        new_coords[:, 1] = np.maximum(np.minimum(new_coords[:, 1] - 1 + tup0[1], 1919), 0)\n",
    "        \n",
    "        B[0, 0, tup0[0] - 1, tup0[1] - 1] = (I_or[0].mean(dim=0)[new_coords.T].mean()/4000)\n",
    "        #print(f\"Iterations: {i}\", end='\\r')\n",
    "    #print(\"End Iterations\" + 70 * ' ')\n",
    "        \n",
    "    B_lbd = fft_conv(180*B, PSF_flipped, padding=512)\n",
    "    B_lbd = torch.clip(B_lbd, 0.0, B_lbd.max().item())\n",
    "    B_lbd[B_lbd == 0] = eps\n",
    "    LCD = torch.clip((I_or)/B_lbd, 0.0, 1.0)\n",
    "    #LCD = gamma_correction(LCD)\n",
    "    T = get_transmittance(LCD, 0.005)\n",
    "\n",
    "    #always between 0.0 and 1.0\n",
    "    I_re = T*B_lbd\n",
    "    \n",
    "    return I_re, LCD, B_lbd, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_mask_coords.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_reconstruct_original_image(I_or: torch.tensor) -> torch.tensor:\n",
    "    B = torch.zeros(1, 1, 1080, 1920).to(device)\n",
    "    eps = 1e-15\n",
    "\n",
    "    B[0, 0][(b_mask_coords - 1).T] = (I_or.max())/4000\n",
    "        \n",
    "    B_lbd = fft_conv(180*B, PSF_flipped, padding=512)\n",
    "    B_lbd = torch.clip(B_lbd, 0.0, B_lbd.max().item())\n",
    "    B_lbd[B_lbd == 0] = eps\n",
    "    LCD = torch.clip((I_or)/B_lbd, 0.0, 1.0)\n",
    "    #LCD = gamma_correction(LCD)\n",
    "    T = get_transmittance(LCD, 0.005)\n",
    "\n",
    "    #always between 0.0 and 1.0\n",
    "    I_re = T*B_lbd\n",
    "    \n",
    "    return I_re, LCD, B_lbd, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_files.pu21_encoder import pu21_encoder\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "\n",
    "def PU_PSNR(true, pred):\n",
    "    pu21 = pu21_encoder(0.005, 4000)\n",
    "    true = pu21.forward(true.cpu())\n",
    "    pred = pu21.forward(pred.cpu())\n",
    "    return PSNR(true.cpu().data.numpy(), pred.cpu().data.numpy(), data_range=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(I_, I):\n",
    "    \"\"\"I_ -- prediction, I -- target, \n",
    "       pa is power_parameter\n",
    "    \"\"\"\n",
    "    #data preprocessing\n",
    "    IM_ = I_[loss_function_mask]\n",
    "    IM  = I[loss_function_mask]\n",
    "    \n",
    "    # L1 smooth loss\n",
    "    loss_f = torch.nn.SmoothL1Loss(beta=1.0)\n",
    "    \n",
    "    loss = loss_f(IM_, IM)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_msssim import MS_SSIM\n",
    "\n",
    "def PU_MSSSIM(true, pred):\n",
    "    pu21 = pu21_encoder(0.005, 4000)\n",
    "    ms_ssim_module = MS_SSIM(data_range=256, size_average=True, channel=3)\n",
    "    true = pu21.forward(true.cpu())\n",
    "    pred = pu21.forward(pred.cpu())\n",
    "    return ms_ssim_module(true.cpu().data, pred.cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import time\n",
    "\n",
    "def test_model(loss_func):\n",
    "    dataloader = test_dataloader\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_pu_msssim = 0.\n",
    "    running_pu_psnr = 0.\n",
    "    running_perf_time = 0\n",
    "    \n",
    "    \n",
    "    running_backlight = 0.\n",
    "    # Iterate over data.\n",
    "    for i, (inputs, pname) in enumerate(dataloader):\n",
    "        max_luminance = 4000\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        #time synchronize since cuda is asynchronous\n",
    "        torch.cuda.synchronize()\n",
    "        start_time = time.time()\n",
    "        \n",
    "        #reconstruction\n",
    "        constructed_preds, LCD, B_lbd, preds = max_reconstruct_original_image(max_luminance*inputs)\n",
    "        \n",
    "        #same as above\n",
    "        torch.cuda.synchronize()\n",
    "        nn_work_time = time.time() - start_time\n",
    "        running_perf_time += nn_work_time\n",
    "        \n",
    "        \n",
    "        \n",
    "        #loss_value and metrics\n",
    "        loss_value = loss_func(max_luminance*inputs, constructed_preds)\n",
    "        pu_msssim = PU_MSSSIM(max_luminance*inputs, constructed_preds)\n",
    "        pu_psnr = PU_PSNR(max_luminance*inputs, constructed_preds)\n",
    "        \n",
    "        #statistics\n",
    "        running_loss += loss_value.item()\n",
    "        running_pu_msssim += pu_msssim.item()\n",
    "        running_pu_psnr += pu_psnr.item()\n",
    "\n",
    "        #print(\"{} nested {}/{} {}-loss: {:.5f}, PU_MSSSIM: {:.5f}, PU_PSNR {:.1f}\" \\\n",
    "              #.format(pname, (i+1), len(dataloader), \n",
    "                      #'test', loss_value.item(), pu_msssim.item(), pu_psnr.item()))\n",
    "        strip_index = pname[0].rfind('/') + 1 \n",
    "        dot_index = pname[0][strip_index:].rfind('.')\n",
    "        \n",
    "        output_str = \"{} loss: {:.2f}, PU_MSSSIM: {:.2f}, PU_PSNR {:.1f}, BACKLIGH_SUM: {:.2f}, MIN_VALUE_RESULT {:.6f}, MAX_VALUE_RESULT {:.2f}, MIN_VALUE_REAL {:.6f}, MAX_VALUE_REAL {:.2f}\" \\\n",
    "                  .format(pname[0][strip_index:], loss_value.item(), pu_msssim.item(), pu_psnr.item(), (b_mask*preds).sum().item(),\n",
    "                          B_lbd.min().item(), B_lbd.max().item(), inputs.min().item(), inputs.max().item())\n",
    "        running_backlight += (b_mask*preds).sum().item()\n",
    "        with open(f\"test_evaluation.txt\", \"a+\") as f:\n",
    "                    f.write(output_str + '\\n')\n",
    "                \n",
    "        name = pname[0][strip_index:]\n",
    "                \n",
    "        #saving lcd\n",
    "        pil_trans = transforms.ToPILImage()\n",
    "        pil_lcd = pil_trans(LCD[0])\n",
    "        pil_lcd.save(os.path.join(test_lcd_dir, name + '.lcd.dld.tif'), compression=None, quality=100)\n",
    "\n",
    "        #saving\n",
    "        #tiff.imsave(os.path.join(test_dir, name + '.out.dld.tif'),\n",
    "        #            (constructed_preds).detach().cpu().numpy())\n",
    "        #low_format\n",
    "        tiff.imsave(os.path.join(test_visual_dir, name + '.out_uint8.dld.tif'),\n",
    "                   (constructed_preds*255).detach().cpu().numpy().astype(np.uint8))\n",
    "        \n",
    "        #reconstruction\n",
    "        tiff.imsave(os.path.join(test_dir, name + '.out_sim.dld.tif'),\n",
    "                    (constructed_preds).detach().cpu().numpy())\n",
    "\n",
    "    #mean_value on epoch\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_pu_msssim = running_pu_msssim/ len(dataloader)\n",
    "    epoch_pu_psnr = running_pu_psnr/ len(dataloader)\n",
    "    epoch_perf_time = running_perf_time / len(dataloader)\n",
    "    epoch_backlight = running_backlight / len(dataloader)\n",
    "\n",
    "    print('{}. {} Loss: {:.4f}, PU_MSSSIM: {:.4f}, PU_PSNR: {:.2f}, PERF_TIME: {:.4f}, BACKLIGHT_MEAN_SUM: {:.2f}'.format(\n",
    "        0, 'test', epoch_loss, epoch_pu_msssim, epoch_pu_psnr, epoch_perf_time, epoch_backlight) + 70*' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(loss_function)\n",
    "#AVG\n",
    "#PU_MSSSIM: 0.9172, PU_PSNR: 21.51, PERF_TIME: 4.5909, BACKLIGHT_MEAN_SUM: 1.69\n",
    "#MAX\n",
    "#PU_MSSSIM: 0.9813, PU_PSNR: 27.74, PERF_TIME: 4.6832, BACKLIGHT_MEAN_SUM: 2.97\n",
    "#GD\n",
    "#PU_MSSSIM: 0.9584, PU_PSNR: 24.97, PERF_TIME: 0.1358, BACKLIGHT_MEAN_SUM: 9.37    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "#shutil.rmtree(test_dir)\n",
    "#shutil.rmtree(test_visual_dir)\n",
    "shutil.rmtree(test_b_dir)\n",
    "shutil.rmtree(test_lcd_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.make_archive('tests', 'zip', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(test_dir, 'zip', 'test_reconstruction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(test_visual_dir, 'zip', 'test_visual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.make_archive('tests_b_reconstruction', 'zip', 'test_b_reconstruction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
