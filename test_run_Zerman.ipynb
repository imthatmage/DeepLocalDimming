{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adafbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models, transforms\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sb\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "import tifffile as tiff\n",
    "\n",
    "#here we have convolution theorem(using fast fourier transform)\n",
    "from python_files.fft_conv import fft_conv\n",
    "\n",
    "#changes crop in dataset and dataset folder and saving\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dirs for model saving\n",
    "test_dir = f'test_reconstruction'\n",
    "test_lcd_dir = f'test_lcd'\n",
    "test_b_dir = f'test_b_reconstruction'\n",
    "test_visual_dir = f'test_visual'\n",
    "os.makedirs(test_dir)\n",
    "os.makedirs(test_b_dir)\n",
    "os.makedirs(test_visual_dir)\n",
    "os.makedirs(test_lcd_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, train=True):\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "    def transform(self, image):\n",
    "        # Transform to tensor\n",
    "        #cr = T.CenterCrop((1080, 1920))\n",
    "        #image = cr(image)\n",
    "        image = TF.to_tensor(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = tiff.imread(self.image_paths[index])\n",
    "        #image = Image.open(self.image_paths[index])\n",
    "        x = self.transform(image)\n",
    "        return x, self.image_paths[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b568eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = glob.glob('small_train/*.tif') #+ glob.glob('DIV2K_valid_HR/*.png')\n",
    "test_data = glob.glob('srgb_linearized_f32/*.tif')\n",
    "#test_data.pop(0)\n",
    "#test_data.pop(0)\n",
    "#test_data.pop(2)\n",
    "\n",
    "test_dataset = Dataset(sorted(test_data))\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=False, num_workers=0, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataloader), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9af058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "PSF_h = 1025\n",
    "PSF_w = 1025\n",
    "\n",
    "file = open(\"zerman_led_psf.csv\")\n",
    "PSF = torch.tensor(np.loadtxt(file, delimiter=\",\")).reshape(1, 1, PSF_h, PSF_w).to(device)\n",
    "print(f\"Mean of PSF:{PSF.mean()}\")\n",
    "sb.displot(PSF.cpu().numpy().flatten())\n",
    "plt.xlim(-0.05, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('Zermans_LEDS_POSITION_2202.json')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "b_mask_coords = np.array(data['grid_coords'])\n",
    "b_mask = torch.zeros(1, 1, 1080, 1920).to(device)\n",
    "for tup in b_mask_coords:\n",
    "    b_mask[0, 0, tup[0] - 1, tup[1] - 1] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80244ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we have all leds on\n",
    "b_psf_full = torch.ones(1, 1, 1080, 1920).type(torch.DoubleTensor).to(device)\n",
    "b_psf_proj = b_mask*b_psf_full\n",
    "b_psf_proj.mean()*(1920*1080)/(2202), b_psf_proj.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flip PSF for 180 degrees\n",
    "PSF_flipped = torch.flip(PSF, dims=[-1, -2])\n",
    "#simulation of luminance with all leds on\n",
    "#PSF_flipped = torch.nn.functional.pad(PSF_flipped, (0,1,0,1), mode='constant')\n",
    "b_psf_output = fft_conv(b_psf_proj, PSF_flipped, padding=512)\n",
    "\n",
    "#here we use 24 because b_psf_output have 24.5(beta)\n",
    "#now 18.5\n",
    "loss_function_mask = b_psf_output > 0.0\n",
    "loss_function_mask = loss_function_mask.expand(1, 3, 1080, 1920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccda8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_files.utils import get_transmittance, tensor_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d213a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_original_image(B_: torch.tensor, I_or: torch.tensor) -> torch.tensor:\n",
    "    B = b_mask*B_\n",
    "    \n",
    "    eps = 1e-15\n",
    "    \n",
    "    B_lbd = fft_conv(180*B, PSF_flipped, padding=512)\n",
    "    B_lbd = torch.clip(B_lbd, 0.0, B_lbd.max().item())\n",
    "    B_lbd[B_lbd == 0] = eps\n",
    "    LCD = torch.clip((I_or)/B_lbd, 0.0, 1.0)\n",
    "    #LCD = gamma_correction(LCD)\n",
    "    T = get_transmittance(LCD, 0.005)\n",
    "\n",
    "    I_re = T*B_lbd\n",
    "    \n",
    "    return I_re, LCD, B_lbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ee3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_fpath, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer, checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_files.pu21_encoder import pu21_encoder\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "\n",
    "def PU_PSNR(true, pred):\n",
    "    pu21 = pu21_encoder(0.005, 4000)\n",
    "    true = pu21.forward(true.cpu())\n",
    "    pred = pu21.forward(pred.cpu())\n",
    "    return PSNR(true.cpu().data.numpy(), pred.cpu().data.numpy(), data_range=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(I_, I, preds):\n",
    "    \"\"\"I_ -- prediction, I -- target, \n",
    "       pa is power_parameter\n",
    "    \"\"\"\n",
    "    #data preprocessing\n",
    "    IM_ = I_[loss_function_mask]\n",
    "    IM  = I[loss_function_mask]\n",
    "    \n",
    "    # L1 smooth loss\n",
    "    loss_f = torch.nn.SmoothL1Loss(beta=1.0)\n",
    "    #loss_f = torch.nn.HuberLoss(delta=512.0)\n",
    "    \n",
    "    loss = loss_f(IM_, IM)\n",
    "    \n",
    "    B = (b_mask*preds).sum()/(2202)\n",
    "    \n",
    "    #loss += 5*B\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cbfc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_msssim import MS_SSIM\n",
    "\n",
    "def PU_MSSSIM(true, pred):\n",
    "    pu21 = pu21_encoder(0.005, 4000)\n",
    "    ms_ssim_module = MS_SSIM(data_range=256, size_average=True, channel=3)\n",
    "    true = pu21.forward(true.cpu())\n",
    "    pred = pu21.forward(pred.cpu())\n",
    "    return ms_ssim_module(true.cpu().data, pred.cpu().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import time\n",
    "\n",
    "def test_model(model, loss_func):\n",
    "    dataloader = test_dataloader\n",
    "    model.eval()\n",
    "    running_loss = 0.\n",
    "    running_pu_msssim = 0.\n",
    "    running_pu_psnr = 0.\n",
    "    running_perf_time = 0.\n",
    "    running_backlight = list()\n",
    "    # Iterate over data.\n",
    "    for i, (inputs, pname) in enumerate(dataloader):\n",
    "        max_lum = 4000\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        #time synchronize since cuda is asynchronous\n",
    "        torch.cuda.synchronize()\n",
    "        start_time = time.time()\n",
    "        preds = model(inputs)\n",
    "        #same as above\n",
    "        torch.cuda.synchronize()\n",
    "        nn_work_time = time.time() - start_time\n",
    "        running_perf_time += nn_work_time\n",
    "        \n",
    "        #reconstruction\n",
    "        constructed_preds, LCD, B_lbd = reconstruct_original_image(preds, 4000*inputs)\n",
    "        \n",
    "        #loss_value and metrics\n",
    "        loss_value = loss_func(4000*inputs, constructed_preds, preds)\n",
    "        pu_msssim = PU_MSSSIM(4000*inputs, constructed_preds)\n",
    "        pu_psnr = PU_PSNR(4000*inputs, constructed_preds)\n",
    "        \n",
    "        #statistics\n",
    "        running_loss += loss_value.item()\n",
    "        running_pu_msssim += pu_msssim.item()\n",
    "        running_pu_psnr += pu_psnr.item()\n",
    "        running_backlight.append((b_mask*preds).sum().item())\n",
    "\n",
    "        #print(\"{} nested {}/{} {}-loss: {:.5f}, PU_MSSSIM: {:.5f}, PU_PSNR {:.1f}\" \\\n",
    "              #.format(pname, (i+1), len(dataloader), \n",
    "                      #'test', loss_value.item(), pu_msssim.item(), pu_psnr.item()))\n",
    "        strip_index = pname[0].rfind('/') + 1 \n",
    "        dot_index = pname[0][strip_index:].rfind('.')\n",
    "        \n",
    "        output_str = \"{} loss: {:.2f}, PU_MSSSIM: {:.2f}, PU_PSNR {:.1f}, BACKLIGHT_SUM {:.2f}, MIN_VALUE_RESULT {:.6f}, MAX_VALUE_RESULT {:.2f}, MIN_VALUE_REAL {:.6f}, MAX_VALUE_REAL {:.2f}\" \\\n",
    "                  .format(pname[0][strip_index:], loss_value.item(), pu_msssim.item(), pu_psnr.item(), (b_mask*preds).sum().item(), \n",
    "                          constructed_preds.min().item(), constructed_preds.max().item(), inputs.min().item(), inputs.max().item())\n",
    "        with open(f\"test_evaluation.txt\", \"a+\") as f:\n",
    "                    f.write(output_str + '\\n')\n",
    "                \n",
    "        #saving lcd\n",
    "        #pil_trans = transforms.ToPILImage()\n",
    "        #pil_lcd = pil_trans(LCD[0])\n",
    "        #pil_lcd.save(os.path.join(test_lcd_dir, pname[0][strip_index:]), compression=None, quality=100)\n",
    "\n",
    "        #saving reconstruction\n",
    "        tiff.imsave(os.path.join(test_dir, pname[0][strip_index:] + '.out_sim.dld.tif'),\n",
    "                    (constructed_preds).detach().cpu().numpy())\n",
    "        #visual\n",
    "        tiff.imsave(os.path.join(test_visual_dir, pname[0][strip_index:] + '.out_uint8.dld.tif'),\n",
    "                   ((constructed_preds/constructed_preds.max())*255).detach().cpu().numpy().astype(np.uint8))\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(24, 4))\n",
    "        #saving backlight\n",
    "        B = torch.clip(B_lbd.reshape(1080, 1920), 0.0, 1.0)\n",
    "        #pil_b = pil_trans(B)\n",
    "        #pil_b.save(os.path.join(test_b_dir, pname[0][strip_index:][:dot_index]) + '.png')\n",
    "        \n",
    "        #show_images\n",
    "        ax[0].imshow((constructed_preds[0]/4000).permute(1, 2, 0).cpu().data.numpy())\n",
    "        ax[1].imshow(LCD[0].permute(1, 2, 0).cpu().data.numpy())\n",
    "        sb.heatmap((B_lbd.reshape(1080, 1920)).cpu().data.numpy(), ax=ax[2], linewidths=0.00, cmap='viridis')\n",
    "        ax[0].grid(False)\n",
    "        ax[0].axis('off')\n",
    "        ax[1].grid(False)\n",
    "        ax[1].axis('off')\n",
    "        ax[2].grid(False)\n",
    "        ax[2].axis('off')    \n",
    "        \n",
    "        ax[0].set_title('LOSS:{:.4f}'.format(loss_value.item()), fontsize=20)\n",
    "        ax[1].set_title('PU_MSSSIM:{:.4f}'.format(pu_msssim.item()), fontsize=20)\n",
    "        ax[2].set_title('PU_PSNR:{:.2f}, B_SUM: {:.1f}'.format(pu_psnr.item(), running_backlight[i]), fontsize=20)\n",
    "        \n",
    "        #plt.savefig(f\"test_visual/{i}.jpg\")\n",
    "    #mean_value on epoch\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_pu_msssim = running_pu_msssim/ len(dataloader)\n",
    "    epoch_pu_psnr = running_pu_psnr/ len(dataloader)\n",
    "    epoch_perf_time = running_perf_time / len(dataloader)\n",
    "    epoch_backlight = sum(running_backlight) / len(dataloader)\n",
    "\n",
    "    print('{}. {} Loss: {:.4f}, PU_MSSSIM: {:.4f}, PU_PSNR: {:.2f}, BACKLIGHT_MEAN_SUM: {:.2f}, PERF_TIME: {:.4f}'.format(\n",
    "        0, 'test', epoch_loss, epoch_pu_msssim, epoch_pu_psnr, epoch_backlight, epoch_perf_time) + 70*' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fee6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1240_2(542), \n",
    "curr_dir = 'seed43124_Zerman_1.0_small'\n",
    "model_list = os.listdir(curr_dir)\n",
    "model_number = model_list.index('224.pt')\n",
    "model_list[model_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a7560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_files.HDRsmall import HDRnet\n",
    "\n",
    "model = HDRnet()\n",
    "#model = torch.nn.DataParallel(model)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "model, optimizer, start_epoch = load_ckp(os.path.join(curr_dir, model_list[model_number]), model, optimizer)\n",
    "#model = model.module\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aeaa8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_model(model, loss_function)\n",
    "#110 205\n",
    "#17.5656, PU_MSSSIM: 0.9854, PU_PSNR: 32.53, BACKLIGHT_MEAN_SUM: 556.49, PERF_TIME: 3.2323\n",
    "#150 210\n",
    "#Loss: 8.4958, PU_MSSSIM: 0.9861, PU_PSNR: 32.76, BACKLIGHT_MEAN_SUM: 669.82, PERF_TIME: 3.1619\n",
    "#90 202\n",
    "#Loss: 7.8785, PU_MSSSIM: 0.9865, PU_PSNR: 32.92, BACKLIGHT_MEAN_SUM: 641.58, PERF_TIME: 3.1742\n",
    "#small 224\n",
    "#Loss: 9.7213, PU_MSSSIM: 0.9837, PU_PSNR: 32.40, BACKLIGHT_MEAN_SUM: 618.34, PERF_TIME: 1.7222 \n",
    "#large 235\n",
    "#Loss: 8.7452, PU_MSSSIM: 0.9855, PU_PSNR: 32.12, BACKLIGHT_MEAN_SUM: 628.00, PERF_TIME: 1.8941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "2000**(1/1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "100**(1/1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(test_dir)\n",
    "shutil.rmtree(test_visual_dir)\n",
    "shutil.rmtree(test_b_dir)\n",
    "shutil.rmtree(test_lcd_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0382a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(test_dir, 'zip', 'test_reconstruction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.make_archive(test_visual_dir, 'zip', 'test_visual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree('seed43124_Zerman_test_120')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
